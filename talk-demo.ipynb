{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slides\n",
    "\n",
    "slides: https://microsoft.sharepoint.com/:p:/t/Vienna/EQR04ke7teRLmRtCaghJ4QwBnFrIqu6sIo4LqAogPdMtTw?e=cXd9cZ\n",
    "\n",
    "https://microsoft-my.sharepoint.com/:p:/p/sejuare/EXAS0v9XvOtMuqttDUItuqoBXzwt78ITVNqUfATM0ffgaA?e=WTHaRK\n",
    "## Setup\n",
    "\n",
    "1. Install the VS Code extension at : https://msasg.visualstudio.com/OpenMind%20Studio/OpenMind%20Studio%20Team/_build/results?buildId=3354388\n",
    "Make sure it has a recent version of the Python SDK -- remove the folder ~/.azureml/envs. A current SDK will be installed when you first use AML from VSCode.\n",
    "2. Install the Python SDK: https://github.com/Azure/ViennaDocs/tree/master/PrivatePreview\n",
    "    make sure to install automl, notebook, and contrib\n",
    "```shell\n",
    "pip install --upgrade azureml-sdk[notebooks,contrib,automl]\n",
    "```\n",
    "3. Clone this repository\n",
    "```shell\n",
    "git clone https://github.com/Azure/AzureMLUsabilityStudy\n",
    "cd ignite\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "## Before each demo\n",
    "* Create a new, empty notebook in the ignite directory of the repo\n",
    "* if you have run this before, make sure you delete mnist_with_summaries.py from the folder ignite_demo\n",
    "* open VSCode at the ignite_demo directory\n",
    "* go to ignite directory and start jupyter notebook there\n",
    "* make sure to bring up the cluster by running\n",
    "\n",
    "```python\n",
    "provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 10, \n",
    "                                                                cluster_max_nodes = 20)\n",
    "\n",
    "nc6_cluster = ComputeTarget.create(ws, \n",
    "                                   name = \"nc6_cluster\", \n",
    "                                   provisioning_configuration=provisioning_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Download Tensorflow  demo code (we will just do this in the browser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = './ignite_demo'\n",
    "import requests\n",
    "import os\n",
    "tf_code = requests.get(\"https://raw.githubusercontent.com/tensorflow/tensorflow/r1.8/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py\")\n",
    "with open(os.path.join(source_folder, \"mnist_with_summaries.py\"), \"w\") as file:\n",
    "    file.write(tf_code.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the script locally (in VSCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the script in VSCode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F2 make sure we import everything -- makes for faster typing and intellisense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.59\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.contrib.tensorboard import Tensorboard\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.train.widgets import RunDetails\n",
    "from azureml.train.hyperdrive import *\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.constants import Metric\n",
    "from ignite_demo.get_data import get_data\n",
    "import time\n",
    "import azureml.core\n",
    "import math\n",
    "\n",
    "source_folder = './ignite_demo'\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F3 This is how you create a workspace (we have already done this before the talk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DanielSc'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.create(name='DanielSc', \n",
    "                      subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', \n",
    "                      resource_group='DanielSc', \n",
    "                      location='eastus2',\n",
    "                      exist_ok=True)\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F4 This is how you create a batch AI cluster (we have already done this before the talk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 10, \n",
    "                                                                cluster_max_nodes = 20)\n",
    "\n",
    "nc6_cluster = ComputeTarget.create(ws, \n",
    "                                   name = \"nc6_cluster\", \n",
    "                                   provisioning_configuration=provisioning_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F5 let's create an experiment in VSCode and then retrieve it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mnist = ws.experiments()['ignite']\n",
    "mnist = Experiment(ws, 'ignite2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F6 now we run the script on our cluster, tracked in the mnist Experiment\n",
    "\n",
    "(what is an estimator, how is tensorflow different, what other estimators are there?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py')\n",
    "\n",
    "run = mnist.submit(tf_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F7 How can we monitor the experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce32e908299439e9bdf745f7400155d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the Accuracy so we can better see the progress of the training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add this at the top of the file\n",
    "```python\n",
    "    from azureml.core.run import Run\n",
    "```\n",
    "2. add 'Run.get_submitted....' near line 165, so you get this\n",
    "```python\n",
    "    print('Accuracy at step %s: %s' % (i, acc))\n",
    "    if i % 50 == 0:\n",
    "        Run.get_submitted_run().log('Accuracy_test', acc)\n",
    "```\n",
    "3. add the same line with different log name further down\n",
    "```python\n",
    "    test_writer.close()\n",
    "    Run.get_submitted_run().log('Accuracy', acc)\n",
    "```\n",
    "\n",
    "4. and add this to log the parameters chosen at the end of the file\n",
    "```python\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    Run.get_submitted_run().log('learning_rate', FLAGS.learning_rate)\n",
    "    Run.get_submitted_run().log('dropout', FLAGS.dropout)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F10 copy the the script over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ignite_demo/mnist_with_summaries.py'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or just run this cell\n",
    "from  shutil import copyfile\n",
    "copyfile('../ignite_misc/save/mnist_with_summaries.py', os.path.join(source_folder, 'mnist_with_summaries.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F11 run the same way as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd3652c513a45188cd0c59d3dddb2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py')\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F12 wasn't there another way to visualize the metrics of a model? Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb281337f6af482e8d8b14187136dd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just add the log_dir parameter\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start Tensorboard\n",
    "\n",
    "Now, while the run is in progress, we just need to start Tensorboard with the run as its target, and it will begin streaming logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://danielscMBP.local:6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://danielscMBP.local:6006'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = Tensorboard(run)\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>ignite2</td><td>ignite2_1537677517789</td><td>azureml.scriptrun</td><td>Finalizing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/DanielSc/providers/Microsoft.MachineLearningServices/workspaces/DanielSc/experiments/ignite2/runs/ignite2_1537677517789\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: ignite2,\n",
       "Id: ignite2_1537677517789,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Finalizing)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Tensorboard\n",
    "\n",
    "When you're done, make sure to call the `stop()` method of the Tensorboard object, or it will stay running even after your job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F8 But, what if my data is not sitting somewhere on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for mnist/t10k-images-idx3-ubyte.gz\n",
      "Target already exists. Skipping upload for mnist/train-images-idx3-ubyte.gz\n",
      "Target already exists. Skipping upload for mnist/train-labels-idx1-ubyte.gz\n",
      "Target already exists. Skipping upload for mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "mnist_data = ds.upload(src_dir = '/Users/danielsc/data/mnist', target_path = 'mnist', show_progress = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F9 Run the same as above but with script_param pointing to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369d3c48788f4442b9bd840596dff758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the same was as above\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Now let's try some different hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff2f103a14944859e9d667942f75c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just adding the hyperparameters\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "    '--learning_rate': 0.0005,\n",
    "    '--dropout': 0.85\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7589455e4224749bddc854f148b8cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same as above but slightly different values\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "    '--learning_rate': 0.01,\n",
    "    '--dropout': 0.5\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99637efd8dd043a8b3e0bbb2312495bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same as above but slightly different values\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "    '--learning_rate': 0.001,\n",
    "    '--dropout': 0.8\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "run = mnist.submit(tf_estimator)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's nice, but all that starting of different runs was a lot of work\n",
    "## 4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but increase the max_steps and remove the parameters\n",
    "script_params={\n",
    "    '--log_dir': './logs',\n",
    "    '--data_dir': mnist_data,\n",
    "    '--max_steps': 5000\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory=source_folder,\n",
    "                          compute_target=nc6_cluster,\n",
    "                          entry_script='mnist_with_summaries.py',\n",
    "                          script_params=script_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. kicking of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc5001b01294abb9e09dc75e5301de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDrive(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--learning_rate': loguniform(-15, -3),\n",
    "        '--dropout': uniform(0.5, 0.95)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator = tf_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"Accuracy_test\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 5)\n",
    "\n",
    "hd_run = mnist.submit(hyperdrive_run_config)\n",
    "\n",
    "RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What if I don't know what type of model to choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f78cb9b76ab45ec8a2d158d34e60ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoML(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path=source_folder,\n",
    "                             compute_target = nc6_cluster,\n",
    "                             data_script = source_folder + \"/get_data.py\",\n",
    "                             max_time_sec = 600,\n",
    "                             iterations = 20,\n",
    "                             n_cross_validations = 5,\n",
    "                             primary_metric = Metric.AUCWeighted,\n",
    "                             concurrent_iterations = 10)\n",
    "\n",
    "remote_run = mnist.submit(automl_config)\n",
    "\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Run ID: AutoML_bc505304-1e3d-4fc6-ba34-3b112e0e44a7\n",
      "***********************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "***********************************************************************************************\n",
      "\n",
      " ITERATION     PIPELINE                               DURATION                METRIC      BEST\n",
      "         0     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your function call closed the pipe prematurely -> Subprocess probably got an uncatchable signal.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages/azureml/train/automl/_limit_function_call.py\", line 304, in __call__\n",
      "    self2.result, self2.exit_status = parent_conn.recv()\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       0:00:06.367580           0.000     0.000\n",
      "ERROR:                                         \n",
      "         1      StandardScalerWrapper KNeighborsClassi0:00:20.744270           0.998     0.998\n",
      "         2      MaxAbsScaler LightGBMClassifier       0:00:23.332491           0.998     0.998\n",
      "         3      MaxAbsScaler DecisionTreeClassifier   0:00:17.269414           0.832     0.998\n",
      "         4      SparseNormalizer LightGBMClassifier   0:00:28.490736           0.998     0.998\n",
      "         5      StandardScalerWrapper KNeighborsClassi0:00:20.767038           0.998     0.998\n",
      "         6      StandardScalerWrapper LightGBMClassifi0:00:26.035480           0.999     0.999\n",
      "         7     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your function call closed the pipe prematurely -> Subprocess probably got an uncatchable signal.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/site-packages/azureml/train/automl/_limit_function_call.py\", line 304, in __call__\n",
      "    self2.result, self2.exit_status = parent_conn.recv()\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/danielsc/miniconda3/envs/preview/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       0:00:05.778395           0.000     0.999\n",
      "ERROR:                                         \n",
      "         8                                            0:14:18.179034           0.000     0.999\n",
      "ERROR: local variable 'dependencies' referenced before assignment\n",
      "Received interrupt. Returning now."
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.constants import Metric\n",
    "from ignite_demo.get_data import get_data\n",
    "import time, logging\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             iterations = 10,\n",
    "                             n_cross_validations = 3,\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = get_data()['X'], \n",
    "                             y = get_data()['y'],\n",
    "                             max_cores_per_iteration = 1,\n",
    "                             enforce_time_on_windows = False,\n",
    "                             path=source_folder)\n",
    "\n",
    "local_run = mnist.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_tf_model\n"
     ]
    }
   ],
   "source": [
    "for m in ws.models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ws.models('mnist_tf_model')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ws.webservices(model_name='mnist_tf_model')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ws.images(model_id=\"mnist_tf_model:1\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mnist_tf_model:1'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf-mnist:1'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aci-service-mnist'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.cname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>tensorflow-hyperdrive</td><td>DanielSc</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/DanielSc/providers/Microsoft.MachineLearningServices/workspaces/DanielSc/experiments/tensorflow-hyperdrive\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: tensorflow-hyperdrive,\n",
       "Workspace: DanielSc)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ws.experiments().values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ws.experiments()['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-9bd8b0def9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'AutoML_865262da-3cbc-41d9-8c9c-90e28a1df6bd_19'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(e.get_runs(properties={'Id':'AutoML_865262da-3cbc-41d9-8c9c-90e28a1df6bd_19'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>test</td><td>AutoML_865262da-3cbc-41d9-8c9c-90e28a1df6bd_19</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/DanielSc/providers/Microsoft.MachineLearningServices/workspaces/DanielSc/experiments/test/runs/AutoML_865262da-3cbc-41d9-8c9c-90e28a1df6bd_19\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: test,\n",
       "Id: AutoML_865262da-3cbc-41d9-8c9c-90e28a1df6bd_19,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(e.get_runs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
