{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demo script\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and examine the version of the Azure ML SDK. This demo was created using the 0.1.65 version of the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version:  0.1.68\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK Version: \", azureml.core.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML Workspaces\n",
    "\n",
    "A workspace is a ... TODO\n",
    "\n",
    "This would be a good time to graphically explore the ```TechSummit``` workspace using Visual Studio Code and the Azure ML extension. You can easily see the different kinds of resources that are there. Note that the Visual Studio Code Azure ML extension makes it easy to work with Azure ML workspaces directly from the editor that you're using to create your code. All of the operations that you can do in Visual Studio Code, including examining experiments etc. can be also done _programmatically_ in Azure Notebooks using the AML SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can interact with a workspace, we first need to acquire a reference to it. Create or open the ```TechSummit``` Azure ML workspace. Before you run this, make sure that you **run the Data/Connect to Azure command** from the Jupyter menu above. This will ensure that your Azure login credentials are made available to the code running in this notebook. If you see a device login prompt, this almost always means that you forgot to run the Data/Connect to Azure command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TechSummit'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name='TechSummit', \n",
    "                      subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', \n",
    "                      resource_group='juliademo', \n",
    "                      location='eastus2',\n",
    "                      exist_ok=True)\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can submit jobs to the cluster that we saw earlier, we need to retrieve a reference to it. Note that the ```nc6cluster``` has already been created earlier in this demo. The ```ComputeTarget.create``` method can be called to either create or retrieve a reference to an existing cluster; it will not return an error if the cluster already exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import BatchAiCompute, ComputeTarget\n",
    "\n",
    "provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 10, \n",
    "                                                                cluster_max_nodes = 20)\n",
    "\n",
    "cluster = ComputeTarget.create(ws, \n",
    "                               name = \"nc6cluster\", \n",
    "                               provisioning_configuration=provisioning_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simple experiment using our Azure Batch AI cluster\n",
    "\n",
    "Let's begin by creating a new experiment called ```TechSummitDemo``` in our workspace, and running the ```tf_mnist.py``` file using it. An **Experiment** constructs a reproducible execution environment for running your model training scripts. It does so by creating a **Docker container** for the execution environment for the experiment. The Docker container is saved to the Azure Container Registry in your **Workspace**, ensuring that you will always be able to come back to reproduce the results of this experiment in the future.\n",
    "\n",
    "Once the container is created, it must be downloaded onto each of the compute nodes on the cluster before the runs can begin. Note that this can take quite some time to complete the first time that you configure the Experiment. But once complete, you now can recreate the environment rapidly by re-running the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"TechSummitDemo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do an experimental run using the ```Experiment``` object that we just created. This experiment takes ~90s to run on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "mnist_data = DataReference(ds, path_on_datastore='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': mnist_data\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory='.',\n",
    "                       compute_target=cluster,\n",
    "                       entry_script='tf_mnist.py',\n",
    "                       script_params=script_params)\n",
    "\n",
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine the ```run``` object, we can see a link to the Azure Portal that shows a summary of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>TechSummitDemo</td><td>TechSummitDemo_1540149174771</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/juliademo/providers/Microsoft.MachineLearningServices/workspaces/TechSummit/experiments/TechSummitDemo/runs/TechSummitDemo_1540149174771\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: TechSummitDemo,\n",
       "Id: TechSummitDemo_1540149174771,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using HyperDrive to do hyper parameter optimization\n",
    "\n",
    "Now that we have a model, the next step is to tune it for hyperdrive parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a reference to the dataset that is stored in the ```TechSummit``` workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the hyperparameter training job. Note that this job takes ~22 minutes to run to completion on the provisioned cluster. So we will need to Julia Child this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'TechSummitDemo_1540149198926',\n",
       " 'target': 'nc6cluster',\n",
       " 'status': 'Completed',\n",
       " 'endTimeUtc': '2018-10-21T19:24:24.000Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"final_acc\", \"goal\": \"maximize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://techsummstorageoqnwcdnj.blob.core.windows.net/azureml/ExperimentRun/TechSummitDemo_1540149198926/azureml-logs/hyperdrive.txt?sv=2017-04-17&sr=b&sig=YFn%2F6qBKexbS%2Fl3l6sQa%2BP1Lb537beqkvd0j44vPBO8%3D&st=2018-10-21T19%3A14%3A25Z&se=2018-10-22T03%3A24%3A25Z&sp=r'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveRunConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import loguniform, uniform\n",
    "\n",
    "script_params={\n",
    "    '--data-folder': mnist_data,\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory='.',\n",
    "                          compute_target=cluster,\n",
    "                          entry_script='tf_mnist.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--learning-rate': loguniform(-15, -3)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator = tf_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"final_acc\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 5)\n",
    "\n",
    "hd_run = experiment.submit(hyperdrive_run_config)\n",
    "hd_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the best model\n",
    "\n",
    "This is where we find the best run in the hyperdrive tuning session, deploy the model to ACI and make a prediction using it. BTW, this method is currently running very slowly. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hd_run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all of the runs in an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'outputs/model/checkpoint', 'outputs/model/mnist-tf.model.data-00000-of-00001', 'outputs/model/mnist-tf.model.index', 'outputs/model/mnist-tf.model.meta', 'driver_log', 'azureml-logs/azureml.log', 'azureml-logs/55_batchai_execution.txt']\n"
     ]
    }
   ],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='tf-dnn-mnist', model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global X, output, sess\n",
    "    tf.reset_default_graph()\n",
    "    model_root = Model.get_model_path('tf-dnn-mnist')\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_root, 'mnist-tf.model.meta'))\n",
    "    X = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\n",
    "    output = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    saver.restore(sess, os.path.join(model_root, 'mnist-tf.model'))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    out = output.eval(session = sess, feed_dict = {X: data})\n",
    "    y_hat = np.argmax(out, axis = 1)\n",
    "    return json.dumps(y_hat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults==0.1.68\n",
      "- numpy\n",
      "- tensorflow=1.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import CondaDependencies\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('numpy')\n",
    "cd.add_tensorflow_conda_package()\n",
    "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'name':'mnist', 'framework': 'TensorFlow DNN'},\n",
    "                                               description='Tensorflow DNN on MNIST from HyperDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "imgconfig = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                               runtime=\"python\", \n",
    "                                               conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image tf-mnist-svc:10, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running..............................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='tf-mnist-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=imgconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://13.68.133.26:80/score'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-7246d9067ead>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('data', False)\n",
    "\n",
    "X_train = mnist.train.images \n",
    "X_test = mnist.test.images \n",
    "\n",
    "y_train = mnist.train.labels \n",
    "y_test = mnist.test.labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://13.68.133.26:80/score\n",
      "label: 2\n",
      "prediction: \"[2]\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x228b75ad6d8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)\n",
    "\n",
    "plt.imshow(X_test[random_index].reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
