{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Demo script\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and examine the version of the Azure ML SDK. This demo was created using the 0.1.65 version of the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version:  0.1.68\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK Version: \", azureml.core.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML Workspaces\n",
    "\n",
    "A workspace is a ... TODO\n",
    "\n",
    "This would be a good time to graphically explore the ```TechSummit``` workspace using Visual Studio Code and the Azure ML extension. You can easily see the different kinds of resources that are there. Note that the Visual Studio Code Azure ML extension makes it easy to work with Azure ML workspaces directly from the editor that you're using to create your code. All of the operations that you can do in Visual Studio Code, including examining experiments etc. can be also done _programmatically_ in Azure Notebooks using the AML SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can interact with a workspace, we first need to acquire a reference to it. Create or open the ```TechSummit``` Azure ML workspace. Before you run this, make sure that you **run the Data/Connect to Azure command** from the Jupyter menu above. This will ensure that your Azure login credentials are made available to the code running in this notebook. If you see a device login prompt, this almost always means that you forgot to run the Data/Connect to Azure command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TechSummit'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name='TechSummit', \n",
    "                      subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', \n",
    "                      resource_group='juliademo', \n",
    "                      location='eastus2',\n",
    "                      exist_ok=True)\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can submit jobs to the cluster that we saw earlier, we need to retrieve a reference to it. Note that the ```nc6cluster``` has already been created earlier in this demo. The ```ComputeTarget.create``` method can be called to either create or retrieve a reference to an existing cluster; it will not return an error if the cluster already exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import BatchAiCompute, ComputeTarget\n",
    "\n",
    "provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 10, \n",
    "                                                                cluster_max_nodes = 20)\n",
    "\n",
    "cluster = ComputeTarget.create(ws, \n",
    "                               name = \"nc6cluster\", \n",
    "                               provisioning_configuration=provisioning_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simple experiment using our Azure Batch AI cluster\n",
    "\n",
    "Let's begin by creating a new experiment called ```TechSummitDemo``` in our workspace, and running the ```mnist_with_summaries.py``` file using it. An **Experiment** constructs a reproducible execution environment for running your model training scripts. It does so by creating a **Docker container** for the execution environment for the experiment. The Docker container is saved to the Azure Container Registry in your **Workspace**, ensuring that you will always be able to come back to reproduce the results of this experiment in the future.\n",
    "\n",
    "Once the container is created, it must be downloaded onto each of the compute nodes on the cluster before the runs can begin. Note that this can take quite some time to complete. But once complete, you now can recreate the environment rapidly by re-running the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"TechSummitDemo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do an experimental run using the ```Experiment``` object that we just created. This experiment takes ~90s to run on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "mnist_data = DataReference(ds, path_on_datastore='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': mnist_data\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory='.',\n",
    "                       compute_target=cluster,\n",
    "                       entry_script='tf_mnist.py',\n",
    "                       script_params=script_params)\n",
    "\n",
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine the ```run``` object, we can see a link to the Azure Portal that shows a summary of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>TechSummitDemo</td><td>TechSummitDemo_1540108915198</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/juliademo/providers/Microsoft.MachineLearningServices/workspaces/TechSummit/experiments/TechSummitDemo/runs/TechSummitDemo_1540108915198\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: TechSummitDemo,\n",
       "Id: TechSummitDemo_1540108915198,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using HyperDrive to do hyper parameter optimization\n",
    "\n",
    "ZZZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a reference to the dataset that is stored in the ```TechSummit``` workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the hyperparameter training job. Note that this job takes ~22 minutes to run to completion on the provisioned cluster. So we will need to Julia Child this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveRunConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import loguniform, uniform\n",
    "\n",
    "script_params={\n",
    "    '--data-folder': mnist_data,\n",
    "}\n",
    "\n",
    "tf_estimator = TensorFlow(source_directory='.',\n",
    "                          compute_target=cluster,\n",
    "                          entry_script='tf_mnist.py',\n",
    "                          script_params=script_params)\n",
    "\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--learning-rate': loguniform(-15, -3)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator = tf_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"final_acc\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 5)\n",
    "\n",
    "hd_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the best model\n",
    "\n",
    "This is where we find the best run in the hyperdrive tuning session, deploy the model to ACI and make a prediction using it. BTW, this method is currently running very slowly. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hd_run.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a list of all of the runs in an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'outputs/model/checkpoint', 'outputs/model/mnist-tf.model.meta', 'outputs/model/mnist-tf.model.index', 'outputs/model/mnist-tf.model.data-00000-of-00001', 'driver_log', 'azureml-logs/azureml.log', 'azureml-logs/55_batchai_execution.txt']\n"
     ]
    }
   ],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='tf-dnn-mnist', model_path='outputs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global X, output, sess\n",
    "    tf.reset_default_graph()\n",
    "    model_root = Model.get_model_path('tf-dnn-mnist')\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_root, 'mnist-tf.model.meta'))\n",
    "    X = tf.get_default_graph().get_tensor_by_name(\"network/X:0\")\n",
    "    output = tf.get_default_graph().get_tensor_by_name(\"network/output/MatMul:0\")\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    saver.restore(sess, os.path.join(model_root, 'mnist-tf.model'))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # make prediction\n",
    "    out = output.eval(session = sess, feed_dict = {X: data})\n",
    "    y_hat = np.argmax(out, axis = 1)\n",
    "    return json.dumps(y_hat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults==0.1.68\n",
      "- numpy\n",
      "- tensorflow=1.10.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import CondaDependencies\n",
    "cd = CondaDependencies.create()\n",
    "cd.add_conda_package('numpy')\n",
    "cd.add_tensorflow_conda_package()\n",
    "cd.save_to_file(base_directory='./', conda_file_path='myenv.yml')\n",
    "\n",
    "print(cd.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'name':'mnist', 'framework': 'TensorFlow DNN'},\n",
    "                                               description='Tensorflow DNN on MNIST from HyperDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "imgconfig = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                               runtime=\"python\", \n",
    "                                               conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image tf-mnist-svc:9, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running......................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name='tf-mnist-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=imgconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-21 09:10:49,620 CRIT Supervisor running as root (no user in config file)\n",
      "2018-10-21 09:10:49,623 INFO supervisord started with pid 1\n",
      "2018-10-21 09:10:50,625 INFO spawned: 'rsyslog' with pid 10\n",
      "2018-10-21 09:10:50,626 INFO spawned: 'program_exit' with pid 11\n",
      "2018-10-21 09:10:50,627 INFO spawned: 'nginx' with pid 12\n",
      "2018-10-21 09:10:50,628 INFO spawned: 'iot' with pid 13\n",
      "2018-10-21 09:10:50,668 INFO spawned: 'gunicorn' with pid 14\n",
      "2018-10-21 09:10:50,709 INFO success: iot entered RUNNING state, process has stayed up for > than 0 seconds (startsecs)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2018-10-21 09:10:51,091 INFO exited: iot (exit status 1; expected)\n",
      "2018-10-21 09:10:52,297 INFO success: rsyslog entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\n",
      "2018-10-21 09:10:52,297 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\n",
      "2018-10-21 09:10:56,302 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\n",
      "{\"logger\": \"gunicorn.error\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:10:57.254833Z\", \"message\": \"Starting gunicorn 19.6.0\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null, \"msg\": \"Starting gunicorn %s\"}\n",
      "{\"logger\": \"gunicorn.error\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:10:57.255899Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (14)\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null, \"msg\": \"Listening at: %s (%s)\"}\n",
      "{\"logger\": \"gunicorn.error\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:10:57.256014Z\", \"message\": \"Using worker: sync\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null, \"msg\": \"Using worker: %s\"}\n",
      "{\"logger\": \"gunicorn.error\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:10:57.257215Z\", \"message\": \"worker timeout is set to 300\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"gunicorn.error\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:10:57.258170Z\", \"message\": \"Booting worker with pid: 30\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null, \"msg\": \"Booting worker with pid: %s\"}\n",
      "Initializing logger\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.256024Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insights client\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.256255Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up request id generator\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.256360Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insight hooks\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.256463Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Invoking user's init function\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "2018-10-21 09:11:03,257 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "2018-10-21 09:11:03,257 | azureml.core.model | DEBUG | version is None. Latest version is 1\n",
      "2018-10-21 09:11:03,258 | azureml.core.model | DEBUG | Found model path at azureml-models/tf-dnn-mnist/1/model\n",
      "2018-10-21 09:11:03.301690: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2018-10-21 09:11:03.302699: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "{\"logger\": \"tensorflow\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.303684Z\", \"message\": \"Restoring parameters from azureml-models/tf-dnn-mnist/1/model/mnist-tf.model\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/tensorflow/python/platform/tf_logging.py\", \"level\": \"INFO\", \"stack_info\": null, \"msg\": \"Restoring parameters from %s\"}\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.316567Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Users's init has completed successfully\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"root\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.317438Z\", \"message\": \"{\\\"apiName\\\": \\\"\\\", \\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Scoring timeout setting is not found. Use default timeout: 3600000 ms\\\"}\", \"path\": \"/var/azureml-app/aml_logger.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"gunicorn.access\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:03.320388Z\", \"message\": \"127.0.0.1 - - [21/Oct/2018:09:11:03 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "{\"logger\": \"gunicorn.access\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"host\": \"wk-caas-a7b64e3dad434a3bb03ab173cb1f514e-de4247108091feba345069\", \"timestamp\": \"2018-10-21T09:11:04.771984Z\", \"message\": \"127.0.0.1 - - [21/Oct/2018:09:11:04 +0000] \\\"GET / HTTP/1.0\\\" 200 7 \\\"-\\\" \\\"Go-http-client/1.1\\\"\", \"path\": \"/home/mmlspark/lib/conda/lib/python3.5/site-packages/gunicorn/glogging.py\", \"level\": \"INFO\", \"stack_info\": null}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://138.91.120.196:80/score'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-120-7246d9067ead>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\jlam\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('data', False)\n",
    "\n",
    "X_train = mnist.train.images \n",
    "X_test = mnist.test.images \n",
    "\n",
    "y_train = mnist.train.labels \n",
    "y_test = mnist.test.labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://138.91.120.196:80/score\n",
      "label: 6\n",
      "prediction: \"[6]\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# send a random row from the test set to score\n",
    "random_index = np.random.randint(0, len(X_test)-1)\n",
    "input_data = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"label:\", y_test[random_index])\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
